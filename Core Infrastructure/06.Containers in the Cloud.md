IaaS: Share compute resources with other developers by using Virtual machines to virtualize the hardware.
- The idea of a container is to give the independent scalability of workloads in PaaS and an abstraction layer of the OS and hardware in IaaS.
- A configurable system lets you install your favorite runtime, web server, database, or middleware, configure the underlying system resources, such as disk space, disk I/O, or networking, and build as you like.
- The smallest unit of compute is an app with its VM. The guest OS might be large, even gigabytes in size, and take minutes to boot. As demand of your application increases, you have to copy and entire VM and boot the guest OS for each instance of your app, which can be slow and costly.

With App Engine, you get access to programming services, so you only need to write your code in self-contained workloads that use these services and include any dependent libraries.
This scales rapidly, but there's no option to fine-tune the underlying architecture to save cost.

For microservices: modular, easily deployable, and scale independently across a group of hosts

### Kubernetes
- Open-source platform for managing containerized workloads and services
- Makes it easy to orchestrate many containers on many hosts, scale them as microservices, and deploy rollouts and rollbacks.
- Is a set of APIs to deploy containers on a set of nodes called a cluster
- Divided into a set of primary components that run as the control plane and a set of nodes that run containers.
- You can describe a set of application and how they should interact with each other and Kubernetes figures how to make that happen.

A pod is smallest unit in Kubernetes that you can create or deploy.

kubectl
get a list of pods: 

`kubectl get pods`

Load balancer with public IP: 

`kubectl expose deployments nginx --port=80 --type=LoadBalancer`

Service is an abstract which defines logical set of pods and a policy by which to access them.
A Service group is a set of Pods and provides a stable endpoint (or fixed IP address)

<code>kubectl get service
kubectl scale
kubectl get deployments
kubectl apply -f nginx-deployment.config</code>

Update new version: `kubectl rollout`

- You can create a Kubernetes cluster with Kubernetes Engine by using the Google cloud console or the gcloud command.
- GKE clusters can be customized and they support different machine types, number of nodes, and network settings.
- Kubernetes provides the mechanisms through which you interact with your cluster.
	- Deploy and manage applications
	- Perform administration tasks
	- Set policies
	- Monitor workload health
- Advanced cluster management features include:
	- Google Cloud's load-balancing for Compute Engine instances
	- Node pools to designate subsets of nodes within a cluster
	- Automatic scaling of your cluster's node instance count
	- Automatic upgrades for your cluster's node software
	- Node auto-repair to maintain node health and availability
	- Logging and monitoring with Google Cloud's operations suite.

### Hybrid and Multi-Cloud
On-Prem:
Spreading the computing workload over two or more networked servers.
Containers break these workloads down into microservices.

### Anthos
- A hybrid and multi-cloud solution
- Framework rests on Kubernetes and GKE On-Prem
- Provides a rich set of tools for monitoring and maintenance.

### LAB: Getting Start with GKE
### Task 1. Confirm that needed APIs are enabled
Kubernetes Engine API

Container Registry API

### Task 2. Start a Kubernetes Engine cluster
<code>export MY_ZONE="us-east1-d"
gcloud container clusters create webfrontend --zone $MY_ZONE --num-nodes 2
kubectl version</code>

### Task 3. Run and deploy a container

<code>kubectl create deploy nginx --image=nginx:1.17.10
kubectl get pods
kubectl expose deployment nginx --port 80 --type LoadBalancer
kubectl get services
kubectl scale deployment nginx --replicas 3</code>
